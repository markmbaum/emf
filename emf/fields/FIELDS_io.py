"""The FIELDS_io module provides a handful of functions for streamlining the file management process required by the old modeling program called FIELDS. There are functions for reading the DAT files generated by FIELDS and converting them into standard csv files (targeting a single DAT file (convert_DAT) or all DAT files in a given directory and all its subdirectories (convert_DAT_walk, which has an additional option to bundle all DAT files found in a given directory inside single xlsx files for easy access.)). There are also functions that write the data in existing CrossSection objects to formatted text files with FLD extensions, to be used as input files with FIELDS instead of using the program's troublesome and error-prone menus to input data. These functions are to_FLD, to_FLDs, and to_FLDs_walk. CrossSection objects are generated by reading from a template excel file, using the load_template function. Converting all the sheets in a template excel file to FLD files is a one line process: fields.to_FLDs(template_file.xlsx)"""

from .. import os, pd

from . import fields_funks
from . import fields_class

#-------------------------------------------------------------------------------
#FUNCTIONS FOR GENERATING INPUT .FLD FILES

#function formats entries and writes them into a .FLD file targeted by ofile
def _write_FLD_entries(ofile, *entries):
    """format entries and writes them into a .FLD file targeted by ofile"""
    for entry in entries:
        if(fields_funks._is_number(entry)):
            if(fields_funks._is_int(entry)):
                w = '{:< d} \n'.format(int(entry))
            else:
                w = '{:< .2f} \n'.format(float(entry))
            if('.' in w):
                idx = w.index('.')
                if('0' in w[:idx]):
                    idx = w.index('0')
                    if(not fields_funks._is_number(w[idx-1])):
                        w = w[:idx] + w[idx+1:]
        else:
            w = str(entry) + '\n'
        ofile.write(w)

def to_FLD(xs, **kw):
    """Create an FLD input file for FIELDS from a CrossSection object
    args:
        xs - CrossSection object
    kw:
        path - output file destination"""
    #check input
    if(not isinstance(xs, fields_class.CrossSection)):
        raise(fields_class.EMFError("""Input argument to to_FLD() must be a CrossSection object, not an input of type: %s Use to_FLDs() for a SectionBook object.""" % str(type(xs))))
    #get a filename
    fn = fields_funks._path_manage(xs.sheet, 'FLD', **kw)
    #write the .FLD file
    ofile = open(fn, 'w')
    #miscellaneous stuff first
    _write_FLD_entries(ofile, xs.sheet, xs.title, 60, xs.soil_resistivity,
            xs.max_dist, xs.step, xs.sample_height, xs.lROW, xs.rROW)
    #number of conductors and ground wires
    Lconds = len(xs.hot)
    _write_FLD_entries(ofile, Lconds)
    Lgrounds = len(xs.gnd)
    _write_FLD_entries(ofile, Lgrounds)
    #write the hot and gnd conductor data in the same format
    for c in xs.hot + xs.gnd:
        _write_FLD_entries(ofile, c.name, c.x, c.y, c.subconds, c.d_cond,
                c.d_bund, 'ED!(I)', c.I, c.V, c.phase)
    #write the ground wire data a second time, in a different format
    for c in xs.gnd:
        _write_FLD_entries(ofile, c.name, c.x, c.y, c.d_cond, 0, 0)
    #close/save
    ofile.close()
    print('FLD file generated: %s' % fn)

def to_FLDs(*args, **kw):
    """Load or recieve a template workbook of CrossSections and convert them all to FLD files
    args:
        can either be a path string to a target template workbook or an
        existing SectionBook object
    kw:
        path - output destination for FLD files"""
    if(type(args[0]) == str):
        #load the template
        sb = fields_funks.load_template(args[0])
        if('path' not in kw):
            kw['path'] = path = os.path.dirname(args[0])
    elif(isinstance(args[0], fields_class.SectionBook)):
        sb = args[0]
    else:
        raise(fields_class.EMFError("""Input argument to to_FLDs() must be a filepath or a SectionBook."""))
    #generate FLD files
    for xs in sb:
        to_FLD(xs, **kw)

def to_FLDs_walk(dirname, **kw):
    """walk a directory and all of its subdirectories for excel workbooks that can be passed to create_FLDs(). The FLD files are generated in the same directory as the template book they come from. To start with the current directory, pass '.' to the dirname argument."""

    #walk the directory tree from the top down
    for (dirpath, dirnames, filenames) in os.walk(dirname):
        #check for excel files
        for fn in filenames:
            if(len(fn) > 5):
                if(fn[-5:] == '.xlsx'):
                    try:
                        to_FLDs(os.path.join(dirpath, fn), path=dirpath)
                    except(IndexError,KeyError,ValueError,IOError,fields_class.EMFError) as e:
                        print('failure to write FLD files from:\n\t%s'
                                % os.path.join(dirpath, fn))
                        if(type(e) is fields_class.EMFError):
                            print('\n\tBecause of EMFError: ' + str(e))

#------------------------------------------------------------------------------
#FUNCTIONS FOR READING/CONVERTING .FLD FILES

def read_FLD(file_path, group_line=1, title_line=2):
    """Read a FLD file in to a CrossSection object. The name of the FLD file is used as the 'sheet' of the resulting CrossSection. The 'group' and 'title' of the CrossSection are set with the group_line and title_line arguments, which refer to lines in the FLD file to use for those properties (indexed from 1, not 0). They should only be set to 1 or 2. The function will attempt to convert conductor names to integers, leaving them as strings if that fails.
    args:
        file_path - string, path to FLD file
    optional args:
        group_line - int, choose which line in the FLD file to use for the
                     'group' property of the returned CrossSection
        title_line - int, choose which line in the FLD file to use for the
                     'title' property of the returned CrossSection
    returns:
        xs - CrossSection object representing the information in the FLD file"""

    #check extension
    fn = fields_funks._check_extension(file_path, 'FLD', """Input file must have a '.FLD' extention""")
    #get a list of lines
    with open(file_path, 'r') as ifile:
        lines = ifile.readlines()
    #the first 11 lines consist of identification information
    #initialize a CrossSection object
    sh = os.path.basename(file_path).replace('.FLD','')
    xs = fields_class.CrossSection(sh)
    xs.group = lines[group_line-1].strip()
    xs.title = lines[title_line-1].strip()
    xs.max_dist = float(lines[4])
    xs.step = float(lines[5])
    xs.sample_height = float(lines[6])
    xs.lROW = float(lines[7])
    xs.rROW = float(lines[8])
    Lconds = int(lines[9])
    Lgrounds = int(lines[10])
    lines = lines[11:] #discard lines 0-10 after they've been used
    #the information for each conductor starts on a line with the conductor
    #name and no spaces before it. The only other lines without padding in front
    #should be lines with negative numbers. So, find all the lines with
    #no padding that aren't negative numbers and split on those lines to get
    #individual conductor information.
    split = [] #a list of the line numbers with conductor names
    for i,line in enumerate(lines):
        if((line[0] != ' ') and (line[0] != '-') and ('ED!(I)' not in line)):
            split.append(i)
    split.append(len(lines))
    #split the lines of the file on the lines with conductor names
    cond_lines = [] #a list of lists, sublists containing the lines for conductors
    for i in range(1,len(split)):
        cl = [i.strip() for i in lines[split[i-1]:split[i]]]
        #if the first line is empty, the conductor has no name, ignore it
        #why do these groups of lines appear in FLD files???
        if(cl[0]):
            cond_lines.append(cl)
    #convert the conductor lines into dicts of Conductor objects
    hot, gnd = {}, {} #hot and grounded conductors
    for lines in cond_lines:
        #get the name of the conductor
        name = str(lines[0])
        if(fields_funks._is_int(name)):
            name = int(name)
        #check for
        #create the Conductor object
        if(len(lines) == 10): #hot conductor
            c = fields_class.Conductor(name,
                dict(x=lines[1], y=lines[2], subconds=lines[3], d_cond=lines[4],
                    d_bund=lines[5], I=lines[7], V=lines[8], phase=lines[9]))
            if(name in hot):
                #if there is a conductor with the same name, it's a potential
                #duplicate. Check to see if all the parameters are the same and
                #ignore it if so.
                if(c != hot[name]):
                    raise(fields_class.EMFError('Cannot parse FLD file. Duplicate hot conductor name "%s" encountered in file: %s' % (name, file_path)))
            else:
                hot[name] = c
        elif(len(lines) == 6): #grounded conductor
            c = fields_class.Conductor(name,
                dict(x=lines[1], y=lines[2], subconds=1, d_cond=lines[3],
                    d_bund=lines[3], I=lines[4], V=0, phase=lines[5]))
            if(name in gnd):
                if(c != gnd[name]):
                    raise(fields_class.EMFError('Cannot parse FLD file. Duplicate grounded conductor name "%s" encountered in file: %s' % (name, file_path)))
            else:
                gnd[name] = c
        else: #unknown
            raise(fields_class.EMFError('Cannot parse FLD file. Number of lines in a group of conductor lines must be 6 or 10.'))
    #add the Conductors to the CrossSection
    for h in hot:
        #check if this is a grounded wire in the "hot" dict
        if(h in gnd):
            #check that the voltage of the Conductor is actually zero
            if(hot[h].V != 0):
                raise(fields_class.EMFError('Cannot parse FLD file. A Conductor with nonzero voltage is listed as a grounded line.'))
            del(gnd[h])
        xs.add_conductor(hot[h])
    for g in gnd:
        xs.add_conductor(gnd[g])

    return(xs)

def read_FLDs(dir_name, group_line=1, title_line=2, ignore_errors=False, **kw):
    """Search for FLD files in a folder/directory and load all detected FLD files into a SectionBook of CrossSections.
    args:
        dir_name - str, to search the current directory, use '.'
    optional args:
        group_line - int, choose which line in the FLD file to use for the
                     'group' property of the returned CrossSection
        title_line - int, choose which line in the FLD file to use for the
                     'title' property of the returned CrossSection
        ignore_errors - bool, errors specific to emf.fields will be ignored if
                        ignore_errors is True. Each FLD file that causes an
                        EMFError will be ignored.
    kw:
        name - str, sets the name of the returned SectionBook. If unused,
               the name is chosen automatically.
    returns:
        sb - SectionBook (empty if no FLD files are found)"""

    #check directory exists
    if(not os.path.isdir(dir_name)):
        raise(fields_class.EMFError('The input directory "%s" does not exist.' % dir_name))
    #get FLD files in the directory, converting them to CrossSections
    xss = []
    for fn in os.listdir(dir_name):
        fnj = os.path.join(dir_name, fn)
        if(os.path.isfile(fnj)):
            if(len(fnj) > 4):
                if(fnj[-3:] == 'FLD'):
                    try:
                        xs = read_FLD(fnj, group_line=group_line, title_line=title_line)
                    except fields_class.EMFError as e:
                        if(not ignore_errors):
                            raise(e)
                        else:
                            print('EMFError ignored:\n%s' % str(e))
                    else:
                        xss.append(xs)
    #check for duplicate xs sheet strings
    for i in range(len(xss)):
        sh1 = xss[i].sheet
        for j in range(i+1, len(xss)):
            sh2 = xss[j].sheet
            if(sh1 == sh2):
                raise(fields_class.EMFError("""The first line of each FLD file is converted to its CrossSection object's "sheet" property. Multiple FLD files in the target directory have the same "sheet" string. The "sheet" strings of each CrossSection must be unique if they are to be added to a SectionBook. Be sure that the first line of each FLD file in the target directory is unique among other FLD files in that directory. The duplicate sheet string was "%s".""" % sh1))
    #create SectionBook
    if('name' in kw):
        name = kw['name']
    elif(dir_name == '.'):
        name = 'unnamed-SectionBook'
    else:
        name = os.path.basename(dir_name)
    sb = fields_class.SectionBook(name, xss)

    return(sb)

#------------------------------------------------------------------------------
#FUNCTIONS FOR CONVERTING OUTPUT .DAT FILES TO CSV/excel FILES

def read_DAT(file_path):
    """Read a DAT file, which can have some funky extra characters if the numbers are too large (percent signs)
    args:
        file_path - string, path to DAT file
    returns:
        df - pandas DataFrame with 'Bx','By','Bprod','Bmax','Ex','Ey','Eprod',
             and 'Emax' columns, and the distance ('x') in the index"""

    #check that the target file is a DAT
    fields_funks._check_extension(file_path, 'DAT', """Input file must have a '.DAT' extension.""")
    #load data
    und_message = 'Electric Field cannot be computed for underground circuit'
    und_only = False
    with open(file_path,'r') as ifile:
        #expect nine columns in the data file
        und_only = False
        ncols = 9
        #read through the header
        line = ifile.readline()
        while(not ('----' in line)):
            line = ifile.readline()
            if(und_message in line):
                und_only = True
                ncols = 5
        #get the data
        data = [[] for i in range(ncols)]
        line = ifile.readline()
        while(line != ''):
            #split the line
            s = line.split()
            if(s):
                #get entries for all columns, even if on different lines
                while(len(s) < ncols):
                    s += ifile.readline().replace('%','').split()
                #remove spurrious % characters
                s = [i.replace('%','') for i in s]
                #store data
                for i in range(ncols):
                    data[i].append(float(s[i]))
            line = ifile.readline()

        #put data in a frame
        cols = ['Bx','By','Bprod','Bmax','Ex','Ey','Eprod','Emax']
        df = pd.DataFrame(dict(zip(cols[:ncols-1], data[1:])), index=data[0])
        df.index.name = 'Distance (ft)'
        if(und_only):
            for col in sorted(cols[ncols-1:]):
                df[col] = 0.0

        return(df)

def convert_DAT(file_path, **kw):
    """Use the read_DAT function to read a DAT file and write it to a csv in the same directory or to a path specified by the "path" keyword argument.
    args:
        file_path - target DAT file
    kw:
        path - output location/name for csv file"""
    #get filename
    if('path' not in kw):
        kw['path'] = os.path.dirname(file_path)
    fn = os.path.basename(file_path).replace('.DAT','')
    fn = fields_funks._path_manage(fn, 'csv', **kw)
    #write csv
    read_DAT(file_path).to_csv(fn, index_label='Distance (ft)')
    print('DAT converted to csv: "%s"' % fn)

def convert_DAT_walk(dirname, bundle=True):
    """Walk a directory and all of its subdirectories, calling the "read_DAT" function on all encountered DAT files. The DAT files in a given directory are either converted to individual csv files or converted to separate sheets in a single excel file, depending on the 'bundle' argument.
    args:
        dirname - directory to initiate the walk in, to designate the
                  current directory, use '.'
    optional args:
        bundle - bool, if True, all DAT files found in the same directory
                 are written to a common excel workbook. If False or absent,
                 the DAT files are simply written to individual csv files."""

    #set an index label for all exported DataFrames
    index_label = 'Distance (ft)'
    #walk the directory tree
    for (dirpath, dirnames, filenames) in os.walk(dirname):
        #set a flag for detection of the first DAT file
        hasdat = False
        #check for DAT files
        for fn in filenames:
            if(len(fn) > 4):
                if(fn[-4:] == '.DAT'):
                    #read file contents into a DataFrame
                    df = read_DAT(os.path.join(dirpath, fn))
                    #export to excel or csv, depending on the value of bundle
                    if(bundle):
                        #if this is the first DAT encountered, switch the flag
                        #and create an excel workbook
                        if(not hasdat):
                            hasdat = True
                            fn_xl = os.path.join(dirpath, 'converted-DATs.xlsx')
                            xl = pd.ExcelWriter(fn_xl, engine='xlsxwriter')
                        #write the DataFrame to a new sheet
                        sh = fn.replace('.DAT','')
                        df.to_excel(xl, sheet_name=sh, index_label=index_label)
                    else:
                        fn_csv = os.path.join(dirpath, fn.replace('.DAT','.csv'))
                        df.to_csv(fn_csv, index_label=index_label)
                        print('converted DAT written to: %s' % fn_csv)
        #if an excel book was created, save it before moving on to the next dir
        if(bundle and hasdat):
            xl.save()
            print('converted DATs written to: %s' % fn_xl)
